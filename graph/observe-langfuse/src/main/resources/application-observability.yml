# OpenTelemetry Observation configuration for Langfuse integration
management:
  endpoints:
    web:
      exposure:
        include: "*"
  endpoint:
    health:
      # health status check with detailed messages
      # show-details: always
      access:
  tracing:
    sampling:
      # trace information with every request
      probability: 1.0
  observations:
    annotations:
      enabled: true

# OpenTelemetry configuration
otel:
  service:
    name: spring-ai-alibaba-deepresearch-langfuse
  resource:
    attributes:
      deployment.environment: development
  # configure exporter
  traces:
    exporter: otlp
    sampler: always_on
  metrics:
    exporter: otlp
  # logs exportation inhibited for langfuse currently cannot support
  logs:
    exporter: none
  exporter:
    otlp:
      # OpenTelemetry exporter endpoint configuration. For details, refer to the official Langfuse documentation: https://langfuse.com/docs/opentelemetry/get-started
      endpoint: "https://us.cloud.langfuse.com/api/public/otel" # ðŸ‡ºðŸ‡¸ US data region
      headers:
        Authorization: "Basic ${YOUR_BASE64_ENCODED_CREDENTIALS}" # echo -n "pk-xxx:sk-xxx" | base64
      protocol: http/protobuf
